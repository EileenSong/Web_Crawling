{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "import emoji\n",
    "import re\n",
    "from soynlp.normalizer import * #반복되는 자음 제거\n",
    "from pykospacing import Spacing #띄어쓰기\n",
    "import time\n",
    "from tqdm.notebook import tqdm #for문 진행률 \n",
    "from time import sleep #for문 진행 시간 \n",
    "import requests #맞춤법 검사\n",
    "import json #맞춤법 검사\n",
    "from kiwipiepy import Kiwi #문장 분리2\n",
    "from collections import Counter\n",
    "\n",
    "okt = Okt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09285f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#의미를 가지고 있는 명사, 형용사, 동사를 konlpy 패키지를 사용하여 추출함.\n",
    "#collections 모듈의 Counter 함수로 단어의 빈도를 구함.\n",
    "#상위 200위 이내 단어를 수정 및 불용어 처리로 2차 정제함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51949b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일불르기\n",
    "df = pd.read_csv(\"D:/2022jasago_news_url_title.csv\", encoding='UTF-8')\n",
    "title_list = list(df['title']) #자연어 전처리를 위해 본문을 리스트 형태로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b150625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 제거_ re를 활용함\n",
    "for i in range(len(title_list)):\n",
    "    title_list[i] = re.sub('[^A-Za-z0-9가-힣]', ' ', string=str(title_list[i])) #한글, 영어, 숫자만 남기기\n",
    "    title_list[i] = repeat_normalize(title_list[i], num_repeats=2) #ㅋㅋ, ㅎㅎ 등의 의미 없는 자음 삭제\n",
    "    \n",
    "df['cleaning'] = pd.DataFrame(title_list) #불용어 제거된 본문을 데이터 프레임으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장 분리\n",
    "kiwi = Kiwi()\n",
    "\n",
    "start = time.time()\n",
    "split_list = [kiwi.split_into_sents(df['cleaning'][i]) for i in tqdm(range(len(df['cleaning'])))]\n",
    "df['split_list'] = split_list\n",
    "end = time.time()\n",
    "\n",
    "print(f\"{end - start:.5f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ffeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한 row\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(len(df['split_list']))):\n",
    "    for j in range(len(df['split_list'][i])):\n",
    "                                                            # 원래 기사의 순서를 index로 저장\n",
    "        split_str= {'split_str': df['split_list'][i][j][0], 'index': [i]}\n",
    "        split_df= pd.DataFrame(split_str)\n",
    "        df2= pd.concat([df2,split_df])\n",
    "        \n",
    "df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#맞춤법\n",
    "modify_list = []\n",
    "\n",
    "def matchum(a):\n",
    "    for i in tqdm(range(len(a))):\n",
    "        try:                                                                               \n",
    "            response = requests.post('http://164.125.7.61/speller/results', data={'text1': a[i]})  # 맞춤법 검사 요청 (requests)    \n",
    "            data = response.text.split('data = [', 1)[-1].rsplit('];', 1)[0] # 응답에서 필요한 내용 추출 (html 파싱)\n",
    "            data = json.loads(data) # 파이썬 딕셔너리 형식으로 변환\n",
    "            orgStr = [err['orgStr'] for err in data['errInfo']] #오류가 담긴 errinfo에서 고쳐야 되는 단어 리스트로 추출 \n",
    "            modify = [err['candWord'] for err in data['errInfo']] #고쳐진 단어도 리스트로 추출\n",
    "            splited = a[i] \n",
    "\n",
    "            #여러 개로 고쳐졌을 때 맨 처음 단어만 선택\n",
    "            for j in range(len(modify)):\n",
    "                if '|'in modify[j]: #여러 개로 고쳐질 경우 문자열이 '|'로 구분되어 있음\n",
    "                    com = re.compile('\\|')\n",
    "                    many = com.search(modify[j])\n",
    "                    modify[j]= modify[j][0:(many.span()[0])]\n",
    "                #틀린 문장 고치기\n",
    "                splited = splited.replace(orgStr[j], modify[j])\n",
    "\n",
    "        except:      \n",
    "            splited = a[i]\n",
    "\n",
    "        modify_list.append(splited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb503643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#마춤 검사\n",
    "matchum(df2['split_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#게시글별로\n",
    "# 문자열로 변환\n",
    "df2[\"modify_str\"]=modify_list\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.groupby('index').agg({'modify_str':' '.join})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc82d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df[['url', 'title', 'cleaning']], df3[['modify_str']]], axis=1)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소\n",
    "hyeong = []\n",
    "for i in tqdm(range(len(df4))):\n",
    "    a = okt.pos(df4['modify_str'][i], norm=True, stem=True)\n",
    "    hyeong.append(a)\n",
    "    \n",
    "\n",
    "len(hyeong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#명사\n",
    "noun_list = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    a = okt.nouns(df4['modify_str'][i])\n",
    "    noun_list.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9342d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#동사와 형용사도 추가\n",
    "for i in range(len(hyeong)):\n",
    "    for a, b in hyeong[i]:\n",
    "        if b == 'Verb':\n",
    "            noun_list[i].append(a)\n",
    "        elif b == 'Adjective':\n",
    "            noun_list[i].append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame({'words':noun_list})\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(words_df))):\n",
    "    words_df['words'][i] = re.sub(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\", \"\", str(words_df['words'][i]))\n",
    "    words_df['words'][i] = ' '.join(words_df['words'][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_csv(\"명사동사형용사.csv\", index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이중리스트 해제_어려움\n",
    "def flatten(data):\n",
    "    #변환된 값을 넣을 빈 리스트 선언\n",
    "    result = []\n",
    "    for i in data:#리스트 안에 리스트 요소의 타입을 확인할 반복문\n",
    "        if type(i) == list: #리스트 안에 요소의 자료형 판별 조건문\n",
    "            result += flatten(i) #리스트 데이터가 리스트일 때 재귀함수로 들어가서 인덱스 꺼내기\n",
    "        else:\n",
    "            result +=[i] #리스트의 데이터가 리스트형이 아닐 때 result에 요소 넣기\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47150826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 빈도수 추출\n",
    "words_list = flatten(noun_list)\n",
    "words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter(words_list)\n",
    "print(len(word_count))\n",
    "word_n_freq = word_count.most_common(2984)\n",
    "word_n_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dceb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어와 빈도 뽑아서 파일로 저장\n",
    "WORD = []\n",
    "FREQ = []\n",
    "\n",
    "for i, j in word_n_freq:\n",
    "    WORD.append(i)\n",
    "    FREQ.append(j)\n",
    "\n",
    "word_n_freq_df = pd.DataFrame({'단어':WORD, '빈도':FREQ})\n",
    "word_n_freq_df.to_excel(\"2022jasago_news_url_title.csv\", encoding='UTF-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46640094",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_n_freq_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
